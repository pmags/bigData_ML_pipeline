# How to handle a large amount of data on Machine Learning pipeline

This project goal is to explore alternatives to handle a large files on a machine learning pipeline. This is a exploration and study project and is inpired by the Cloud Computing and Big Data carrear from Faculdade de CiÃªncias do Porto.

For this project i will be using a dataset for patient visits to a Emergency room with 4.5G zipped. Depending on the local machine, this pipeline could be handled with locally using multiprocess. Since the goal is to explore alternatives i will be testing the following alternatives:

1. Google Biguqery
2. Apache Beam with dataflow runner

## How to run this project

